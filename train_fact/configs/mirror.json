{"diffusion": {"target": "ldm.models.diffusion.ldm.LatentDiffusion", "params": {"linear_start": 0.00085, "linear_end": 0.012, "timesteps": 1000}}, "model": {"target": "ldm.modules.diffusionmodules.openaimodel.UNetModel", "params": {"image_size": 64, "in_channels": 4, "out_channels": 4, "model_channels": 320, "attention_resolutions": [4, 2, 1], "num_res_blocks": 2, "channel_mult": [1, 2, 4, 4], "num_heads": 8, "transformer_depth": 1, "context_dim": 768, "fuser_type": "gatedSA", "use_checkpoint": true, "face_prob": 1.0, "local_fac_prj": {"target": "rep_merge.Face_Prj", "params": {"in_channel": 144, "out_channel": 196, "in_dim": 512, "out_dim": 768, "mult": 1, "layer_num": 4, "glu": true, "dropout": 0.0, "face_batch": 3, "id_batch": 3}}, "global_fac_prj": {"target": "rep_merge.Face_Prj", "params": {"in_channel": 1, "out_channel": 1, "in_dim": 512, "out_dim": 768, "mult": 1, "layer_num": 4, "glu": true, "dropout": 0.0}}}}, "autoencoder": {"target": "ldm.models.autoencoder.AutoencoderKL", "params": {"scale_factor": 0.18215, "embed_dim": 4, "ddconfig": {"double_z": true, "z_channels": 4, "resolution": 256, "in_channels": 3, "out_ch": 3, "ch": 128, "ch_mult": [1, 2, 4, 4], "num_res_blocks": 2, "attn_resolutions": [], "dropout": 0.0}}}, "text_encoder": {"target": "ldm.modules.encoders.modules.FrozenCLIPEmbedder", "params": {"version": "./pretrained_model/CLIP"}}, "train_dataset_names": {"ADESemantic": {"prob_use_caption": 1, "image_size": 512, "random_flip": true}}, "local_face_tokenizer_input": {"target": "local_face_tokenizer_input.Local_Face_Rep_Input"}, "global_fac_prj": {"target": "rep_merge.Face_Prj"}, "face_extractor": {"target": "face_inference.Face_Extractor", "params": {"name": "vits", "weight": "./pretrained_model/ms1mv2_model_TransFace_S.pt"}}}